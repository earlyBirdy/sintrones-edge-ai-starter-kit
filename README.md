# ðŸ“¦ Sintrones Edge AI Starter Kit

> **â€œEdge AI Vision + Sensor Gatewayâ€ for Vehicle / Factory / City Use**

This open-source project demonstrates how to deploy real-time AI object detection, sensor data fusion, and industrial dashboards using **Sintrones rugged edge AI hardware**. Itâ€™s built for system integrators, developers, and researchers working in transportation, manufacturing, and smart infrastructure.

---

## ðŸš€ Features

- ðŸ“· Use real camera + industrial sensor inputs (USB, PoE, RS232, etc.)
- ðŸ§  Deploy AI models like YOLOv5 or OpenVINO for object detection
- ðŸ“Š Display data and AI results via Streamlit or Grafana dashboard
- ðŸ”Œ Communicate via **MQTT**, **Modbus**, or **CANBus**
- ðŸ“¡ Optional integration of **5G modules + GPS** for mobile/vehicular use
- ðŸ”„ Built-in OTA update agent for field-deployed upgrades

---

## ðŸ› ï¸ Project Structure

```
sintrones-edge-ai-starter-kit/
â”œâ”€â”€ ai_models/             # YOLOv5 or OpenVINO model files
â”œâ”€â”€ sensor_drivers/        # CANbus, Modbus, GPIO, MQTT handlers
â”œâ”€â”€ dashboard/             # Streamlit and Grafana dashboard configs
â”œâ”€â”€ docker/                # Dockerfile + docker-compose.yml
â”œâ”€â”€ app/                   # Core application logic
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ ota/                   # OTA update agent and JSON control
â”œâ”€â”€ configs/               # System & sensor configuration files
â”œâ”€â”€ examples/              # Application-specific integration (vehicle, factory, city)
â”œâ”€â”€ docs/                  # Wiring diagrams, ABOX-5220 architecture
â”‚   â””â”€â”€ index.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ INSTALL.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
```

---


## ðŸ“¦ Deployment Options

| Mode             | Description                                  |
|------------------|----------------------------------------------|
| **Standalone**   | Fully offline dashboard & sensor integration |
| **Edge-to-Cloud**| MQTT to Odoo, AWS, or other IoT platforms     |
| **Vehicle AI**   | Add GPS/CANbus for on-road deployments       |

---

## ðŸŽ¯ Use Cases

- ðŸ“¦ **Smart Logistics** â€“ Detect vehicles or goods, monitor temperature/vibration
- ðŸ­ **Factory Automation** â€“ Visual inspection + machine health monitoring
- ðŸ™ï¸ **Smart Cities** â€“ Public space detection, traffic analytics, air quality

---

## ðŸ“š Additional Resources

- ðŸ“˜ [Use Cases](/docs/USE_CASES.md): Real-world Edge AI applications in factories, vehicles, and smart cities  
- ðŸ¤ [Contributing Guide](/docs/CONTRIBUTING.md): How to get involved and contribute to this project

---

## ðŸ¤ Sales + Technical Collaboration

This starter kit aligns with Sintronesâ€™ efforts to:
- Support system integrators and OEMs with demo-ready tools
- Collaborate on R&D and proof-of-concepts
- Promote industrial AI adoption across SEA & global markets

Use it as a base to build your own PoC, integrate with Odoo IoT, or contribute modules!

---

## âš¡ Getting Started

1. **Clone the repository:**
   ```bash
   git clone https://github.com/sintrones/edge-ai-starter-kit.git
   cd edge-ai-starter-kit
   ```

2. **Install Python dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the dashboard demo:**
   ```bash
   python app/main.py
   ```

## Vision Inspection Camera Publisher

This example publishes **per-frame detections** to MQTT for the collector to ingest. It supports a real ONNX model or a mock fallback.

### 1) Install dependencies
```bash
# Core
python -m pip install onnxruntime opencv-python paho-mqtt

# Apple Silicon (M1/M2/M3): use the silicon wheel
# python -m pip install onnxruntime-silicon opencv-python paho-mqtt
```

### 2) Prepare a model (optional)
If you already have an ONNX model (e.g., YOLO export), put it in `models/defect_detector.onnx`.

Otherwise, generate a tiny test model (always outputs one detection):
```bash
python models/onnx-model-generator/generate_dummy_onnx_with_onnx.py
# -> writes models/defect_detector.onnx
```

> **Note:** If you see an error like *Unsupported model IR version: 11, max supported IR version: 10*, either upgrade onnxruntime (`pip install --upgrade onnxruntime` or `onnxruntime-silicon`) or regenerate the model with IR=10.

### 3) Run the camera publisher
Use a webcam:
```bash
python examples/vision_inspection/camera_infer.py \
  --model models/defect_detector.onnx --camera 0
```
Or a sample video:
```bash
python examples/vision_inspection/camera_infer.py \
  --model models/defect_detector.onnx --video path/to/sample.mp4
```

If you donâ€™t have a model yet, run the mock-fallback script (publishes synthetic detections periodically):
```bash
python onnx-model-generator-ready/camera_infer_mock_fallback.py --camera 0
# or
python onnx-model-generator-ready/camera_infer_mock_fallback.py --video path/to/sample.mp4
```

```bash
# Collector should already be running to write JSONL
python -m src.cli collect --config configs/config.yaml

# Batch to Parquet
python -m src.cli batch --config configs/config.yaml
```

### 4) MQTT topics (default)
- `factory/vision/detections` â€“ raw detections (per frame)
- `factory/vision/events` â€“ filtered/decided events (if you wire through decision engine)

### 5) Troubleshooting
- **Model not found**: ensure `models/defect_detector.onnx` exists or pass an absolute path with `--model`.
- **Unsupported IR version**: upgrade `onnxruntime` or re-generate model with IR=10.
- **No camera**: use `--video` with a test clip.
- **Broker connection**: start Mosquitto locally or point to your broker in `examples/vision_inspection/camera_infer.py` (MQTT_HOST/PORT).

---

## ðŸ“¢ Community & Contact

- [Website](https://www.sintrones.com)
- [LinkedIn](https://www.linkedin.com/company/sintrones-technology-corp/posts/?feedView=all)
- [Edge AI Community (Coming soon)](#)

ðŸ“¬ Want a hardware demo kit? [Contact Sintrones](https://www.sintrones.com/contact/)

---

## ðŸ“„ License

MIT License â€” open for research, testing, and pilot deployment.
